{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import nilearn as nil\n",
    "import nilearn.datasets\n",
    "import nilearn.connectome\n",
    "import nilearn.input_data\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "import simexp_gcn\n",
    "import simexp_gcn.data.raw_data_loader\n",
    "import simexp_gcn.data.time_windows_dataset\n",
    "import simexp_gcn.features.graph_construction\n",
    "import simexp_gcn.models.yu_gcn\n",
    "\n",
    "print(\"torch v{}\".format(torch.__version__))\n",
    "print(\"nilearn v{}\".format(nil.__version__))\n",
    "print(\"simexp_gcn v{}\".format(simexp_gcn.__version__))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ltetrel/.local/lib/python3.6/site-packages/nilearn/datasets/__init__.py:89: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  \"Numpy arrays.\", FutureWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch v1.8.1+cpu\n",
      "nilearn v0.8.0\n",
      "simexp_gcn v0.1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initial parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# parameters\n",
    "num_parcels = 512 # number of parcels (nodes) to keep for the graph\n",
    "window_length = 50 #number of timepoints per sample (timeserie)\n",
    "zero_padding = True #pad splitted timeseries with zeros, or remove incomplete\n",
    "random_seed = 0 # fix random state for dat ageneration, and pytorch fit\n",
    "# paths\n",
    "model_path = os.path.join(\"..\", \"models\", \"gcn_test.pt\")\n",
    "raw_dir = os.path.join(\"..\", \"data\", \"raw\")\n",
    "data_dir = os.path.join(\"..\", \"data\", \"processed\", f\"cobre_difumo{num_parcels}\")\n",
    "ts_out = os.path.join(data_dir, \"timeseries\")\n",
    "conn_out = os.path.join(data_dir, \"connectomes\")\n",
    "\n",
    "if not os.path.exists(ts_out):\n",
    "    os.makedirs(ts_out)\n",
    "if not os.path.exists(conn_out):\n",
    "    os.makedirs(conn_out)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset fetching and connectomes generation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Fetching atlas\n",
    "atlas = nil.datasets.fetch_atlas_difumo(data_dir=raw_dir, dimension=num_parcels)\n",
    "atlas_filename = atlas['maps']\n",
    "atlas_labels = atlas['labels']\n",
    "\n",
    "# Fetching data\n",
    "data = nil.datasets.fetch_cobre(data_dir=raw_dir, n_subjects=None) #all subs"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/ltetrel/.local/lib/python3.6/site-packages/numpy/lib/npyio.py:2349: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  output = genfromtxt(fname, **kwargs)\n",
      "/home/ltetrel/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:85: DeprecationWarning: Function fetch_cobre is deprecated; 'fetch_cobre' has been deprecated and will be removed in release 0.9 . Please consider using a different datasets or downloading it with a different tool than nilearn.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Estimating connectomes\n",
    "# import numpy as np\n",
    "\n",
    "# masker = nil.input_data.NiftiMapsMasker(maps_img=atlas['maps'], standardize=True, verbose=5)\n",
    "# corr_measure = nil.connectome.ConnectivityMeasure(kind=\"correlation\")\n",
    "\n",
    "# for i in range(len(data.func)):\n",
    "#     ts = masker.fit_transform(data.func[i], confounds=data.confounds[i])\n",
    "#     conn = corr_measure.fit_transform([ts])[0]\n",
    "#     sub_num = os.path.basename(data.func[i]).split('.')[0].split('_')[1]\n",
    "#     np.save(os.path.join(ts_out, \"timeseries_{}_difumo_{}.npy\".format(sub_num, num_parcels)), ts)\n",
    "#     np.save(os.path.join(conn_out, \"conn_{}_difumo_{}.npy\".format(sub_num, num_parcels)), conn)\n",
    "#     print(\"Done {}/146\".format(i+1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data generator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Preparing data for generator\n",
    "# this include timeseries loading, splitting and labeling\n",
    "pheno_path = os.path.join(raw_dir, \"cobre\", \"phenotypic_data.tsv\")\n",
    "split_dir = os.path.join(\"..\", \"data\", \"interim\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# remove previous content\n",
    "if os.path.exists(split_dir):\n",
    "    import glob\n",
    "\n",
    "    files = glob.glob(os.path.join(split_dir, \"[^.gitkeep]*\"))\n",
    "    for f in files:\n",
    "        os.remove(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\n",
    "RawDataLoad = simexp_gcn.data.raw_data_loader.RawDataLoader(\n",
    "    num_nodes = num_parcels\n",
    "    , ts_dir=ts_out\n",
    "    , conn_dir=conn_out\n",
    "    , pheno_path=pheno_path)\n",
    "RawDataLoad.split_timeseries_and_save(window_length=window_length, zero_padding=zero_padding, output_dir=split_dir)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "../simexp_gcn/data/raw_data_loader.py:103: UserWarning: Different shapes for sub ID(s): ['40075']\n",
      "  warnings.warn(\"Different shapes for sub ID(s): {}\".format(non_valid_ids))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Pytorch dataset: generates items from the current data directory\n",
    "train_dataset = simexp_gcn.data.time_windows_dataset.TimeWindowsDataset(\n",
    "    data_dir=split_dir\n",
    "    , partition=\"train\"\n",
    "    , random_seed=random_seed\n",
    "    , pin_memory=True\n",
    "    , normalize=True)\n",
    "valid_dataset = simexp_gcn.data.time_windows_dataset.TimeWindowsDataset(\n",
    "    data_dir=split_dir\n",
    "    , partition=\"valid\"\n",
    "    , random_seed=random_seed\n",
    "    , pin_memory=True\n",
    "    , normalize=True)\n",
    "test_dataset = simexp_gcn.data.time_windows_dataset.TimeWindowsDataset(\n",
    "    data_dir=split_dir\n",
    "    , partition=\"test\"\n",
    "    , random_seed=random_seed\n",
    "    , pin_memory=True\n",
    "    , normalize=True)\n",
    "print(\"train dataset: {}\".format(train_dataset))\n",
    "print(\"valid dataset: {}\".format(valid_dataset))\n",
    "print(\"test dataset: {}\".format(test_dataset))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train dataset: 304*(torch.Size([512, 50]), ())\n",
      "valid dataset: 87*(torch.Size([512, 50]), ())\n",
      "test dataset: 44*(torch.Size([512, 50]), ())\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Pytorch dataloader: wraps an iterable around the pytorch dataset to shuffle and generate (in parrallel) minibatches\n",
    "#setting pytoch seed for reproducible torch.utils.data.DataLoader\n",
    "torch.manual_seed(random_seed)\n",
    "train_generator = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_generator = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=True)\n",
    "test_generator = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "train_features, train_labels = next(iter(train_generator))\n",
    "print(f\"Feature batch shape: {train_features.size()}; mean {torch.mean(train_features)}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}; mean {torch.mean(torch.Tensor.float(train_labels))}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature batch shape: torch.Size([16, 512, 50]); mean 1.210719302591201e-09\n",
      "Labels batch shape: torch.Size([16]); mean 0.5625\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model definition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# model definition\n",
    "# get average connectome with its k-nearest neighbors\n",
    "connectomes = RawDataLoad.get_valid_connectomes()\n",
    "graph = simexp_gcn.features.graph_construction.make_group_graph(connectomes, k=8, self_loops=False, symmetric=True)\n",
    "# Create model\n",
    "gcn = simexp_gcn.models.yu_gcn.LoicGCN(graph.edge_index, graph.edge_attr, n_timepoints=window_length)\n",
    "gcn"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LoicGCN(\n",
       "  (conv1): ChebConv(50, 32, K=2, normalization=sym)\n",
       "  (conv2): ChebConv(32, 32, K=2, normalization=sym)\n",
       "  (conv3): ChebConv(32, 16, K=2, normalization=sym)\n",
       "  (fc1): Linear(in_features=8192, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss, current = loss.item(), batch * len(X)\n",
    "        correct = (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        correct /= X.shape[0]\n",
    "        print(f\"#{batch:>5};\\ttrain_loss: {loss:>0.3f};\\ttrain_accuracy: {(100*correct):>5.1f}%\\t\\t[{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def valid_test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model.forward(X)\n",
    "            loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    loss /= size\n",
    "    correct /= size\n",
    "\n",
    "    return loss, correct"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Train and evaluate the model\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gcn.parameters(), lr=1e-4, weight_decay=5e-4)\n",
    "\n",
    "epochs = 15\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}/{epochs}\\n-------------------------------\")\n",
    "    train_loop(train_generator, gcn, loss_fn, optimizer)\n",
    "    loss, correct = valid_test_loop(valid_generator, gcn, loss_fn)\n",
    "    print(f\"Valid metrics:\\n\\t avg_loss: {loss:>8f};\\t avg_accuracy: {(100*correct):>0.1f}%\")\n",
    "print(\"Done!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.826;\ttrain_accuracy:  37.5%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.507;\ttrain_accuracy:  81.2%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 1.492;\ttrain_accuracy:  50.0%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.709;\ttrain_accuracy:  56.2%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 0.819;\ttrain_accuracy:  56.2%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 2.008;\ttrain_accuracy:  31.2%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 1.182;\ttrain_accuracy:  25.0%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.791;\ttrain_accuracy:  56.2%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 1.291;\ttrain_accuracy:  31.2%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.971;\ttrain_accuracy:  62.5%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 1.031;\ttrain_accuracy:  50.0%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.659;\ttrain_accuracy:  56.2%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.793;\ttrain_accuracy:  43.8%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.754;\ttrain_accuracy:  50.0%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.866;\ttrain_accuracy:  37.5%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.676;\ttrain_accuracy:  68.8%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 1.359;\ttrain_accuracy:  25.0%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.641;\ttrain_accuracy:  68.8%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.870;\ttrain_accuracy:  37.5%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.057372;\t avg_accuracy: 43.7%\n",
      "Epoch 2/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.689;\ttrain_accuracy:  56.2%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.720;\ttrain_accuracy:  62.5%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 0.626;\ttrain_accuracy:  75.0%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.697;\ttrain_accuracy:  62.5%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 1.184;\ttrain_accuracy:  31.2%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 0.716;\ttrain_accuracy:  56.2%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 0.797;\ttrain_accuracy:  56.2%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.845;\ttrain_accuracy:  25.0%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 0.757;\ttrain_accuracy:  56.2%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.835;\ttrain_accuracy:  50.0%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 0.797;\ttrain_accuracy:  56.2%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.827;\ttrain_accuracy:  50.0%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.598;\ttrain_accuracy:  68.8%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.669;\ttrain_accuracy:  62.5%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.985;\ttrain_accuracy:  50.0%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.887;\ttrain_accuracy:  50.0%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 0.693;\ttrain_accuracy:  62.5%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.682;\ttrain_accuracy:  50.0%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.680;\ttrain_accuracy:  62.5%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.048960;\t avg_accuracy: 55.2%\n",
      "Epoch 3/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.705;\ttrain_accuracy:  50.0%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.654;\ttrain_accuracy:  68.8%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 0.753;\ttrain_accuracy:  50.0%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.548;\ttrain_accuracy:  81.2%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 0.685;\ttrain_accuracy:  68.8%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 0.698;\ttrain_accuracy:  56.2%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 0.772;\ttrain_accuracy:  50.0%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.523;\ttrain_accuracy:  81.2%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 0.663;\ttrain_accuracy:  62.5%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.688;\ttrain_accuracy:  62.5%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 0.656;\ttrain_accuracy:  56.2%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.707;\ttrain_accuracy:  43.8%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.618;\ttrain_accuracy:  62.5%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.738;\ttrain_accuracy:  43.8%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.503;\ttrain_accuracy:  81.2%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.692;\ttrain_accuracy:  62.5%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 0.835;\ttrain_accuracy:  50.0%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.763;\ttrain_accuracy:  43.8%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.582;\ttrain_accuracy:  68.8%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.052308;\t avg_accuracy: 40.2%\n",
      "Epoch 4/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.581;\ttrain_accuracy:  75.0%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.647;\ttrain_accuracy:  56.2%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 0.731;\ttrain_accuracy:  56.2%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.576;\ttrain_accuracy:  68.8%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 0.596;\ttrain_accuracy:  62.5%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 0.621;\ttrain_accuracy:  62.5%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 0.509;\ttrain_accuracy:  87.5%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.589;\ttrain_accuracy:  68.8%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 0.652;\ttrain_accuracy:  43.8%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.486;\ttrain_accuracy:  75.0%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 0.784;\ttrain_accuracy:  56.2%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.618;\ttrain_accuracy:  68.8%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.691;\ttrain_accuracy:  56.2%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.512;\ttrain_accuracy:  87.5%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.680;\ttrain_accuracy:  62.5%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.623;\ttrain_accuracy:  62.5%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 0.507;\ttrain_accuracy:  81.2%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.710;\ttrain_accuracy:  62.5%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.500;\ttrain_accuracy:  81.2%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.060522;\t avg_accuracy: 43.7%\n",
      "Epoch 5/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.581;\ttrain_accuracy:  68.8%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.626;\ttrain_accuracy:  68.8%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 0.527;\ttrain_accuracy:  81.2%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.823;\ttrain_accuracy:  56.2%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 0.621;\ttrain_accuracy:  68.8%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 0.498;\ttrain_accuracy:  87.5%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 0.705;\ttrain_accuracy:  68.8%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.700;\ttrain_accuracy:  56.2%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 0.526;\ttrain_accuracy:  75.0%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.452;\ttrain_accuracy:  81.2%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 0.718;\ttrain_accuracy:  56.2%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.535;\ttrain_accuracy:  75.0%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.453;\ttrain_accuracy:  75.0%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.583;\ttrain_accuracy:  62.5%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.518;\ttrain_accuracy:  68.8%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.541;\ttrain_accuracy:  68.8%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 0.611;\ttrain_accuracy:  56.2%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.630;\ttrain_accuracy:  62.5%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.909;\ttrain_accuracy:  43.8%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.051082;\t avg_accuracy: 56.3%\n",
      "Epoch 6/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.569;\ttrain_accuracy:  56.2%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.603;\ttrain_accuracy:  68.8%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 0.520;\ttrain_accuracy:  68.8%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.623;\ttrain_accuracy:  75.0%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 0.505;\ttrain_accuracy:  75.0%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 0.518;\ttrain_accuracy:  62.5%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 0.499;\ttrain_accuracy:  81.2%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.560;\ttrain_accuracy:  68.8%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 0.563;\ttrain_accuracy:  75.0%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.485;\ttrain_accuracy:  81.2%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 0.549;\ttrain_accuracy:  62.5%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.674;\ttrain_accuracy:  81.2%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.469;\ttrain_accuracy:  75.0%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.607;\ttrain_accuracy:  62.5%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.633;\ttrain_accuracy:  56.2%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.525;\ttrain_accuracy:  81.2%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 0.437;\ttrain_accuracy:  81.2%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.433;\ttrain_accuracy:  75.0%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.434;\ttrain_accuracy:  81.2%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.075952;\t avg_accuracy: 35.6%\n",
      "Epoch 7/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.448;\ttrain_accuracy:  87.5%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.855;\ttrain_accuracy:  50.0%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 0.555;\ttrain_accuracy:  68.8%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.375;\ttrain_accuracy:  93.8%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 0.492;\ttrain_accuracy:  75.0%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 0.446;\ttrain_accuracy:  75.0%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 0.486;\ttrain_accuracy:  87.5%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.675;\ttrain_accuracy:  56.2%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 0.438;\ttrain_accuracy:  81.2%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.721;\ttrain_accuracy:  56.2%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 0.420;\ttrain_accuracy:  81.2%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.591;\ttrain_accuracy:  56.2%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.579;\ttrain_accuracy:  75.0%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.535;\ttrain_accuracy:  68.8%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.588;\ttrain_accuracy:  68.8%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.549;\ttrain_accuracy:  62.5%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 0.555;\ttrain_accuracy:  68.8%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.666;\ttrain_accuracy:  56.2%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.608;\ttrain_accuracy:  75.0%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.065822;\t avg_accuracy: 49.4%\n",
      "Epoch 8/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.573;\ttrain_accuracy:  56.2%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.560;\ttrain_accuracy:  75.0%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 0.371;\ttrain_accuracy:  93.8%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.543;\ttrain_accuracy:  75.0%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 0.478;\ttrain_accuracy:  87.5%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 0.452;\ttrain_accuracy:  81.2%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 0.576;\ttrain_accuracy:  62.5%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.554;\ttrain_accuracy:  68.8%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 0.433;\ttrain_accuracy:  81.2%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.415;\ttrain_accuracy:  93.8%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 0.381;\ttrain_accuracy:  87.5%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.592;\ttrain_accuracy:  62.5%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.439;\ttrain_accuracy:  87.5%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.421;\ttrain_accuracy:  75.0%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.660;\ttrain_accuracy:  68.8%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.433;\ttrain_accuracy:  75.0%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 0.488;\ttrain_accuracy:  81.2%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.526;\ttrain_accuracy:  87.5%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.432;\ttrain_accuracy:  81.2%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.052298;\t avg_accuracy: 59.8%\n",
      "Epoch 9/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.780;\ttrain_accuracy:  31.2%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.564;\ttrain_accuracy:  50.0%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 0.487;\ttrain_accuracy:  75.0%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.519;\ttrain_accuracy:  68.8%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 0.419;\ttrain_accuracy:  68.8%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 0.574;\ttrain_accuracy:  50.0%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 0.440;\ttrain_accuracy:  81.2%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.443;\ttrain_accuracy:  75.0%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 0.468;\ttrain_accuracy:  81.2%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.363;\ttrain_accuracy:  93.8%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 0.469;\ttrain_accuracy:  87.5%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.325;\ttrain_accuracy:  93.8%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.343;\ttrain_accuracy: 100.0%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.381;\ttrain_accuracy:  93.8%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.402;\ttrain_accuracy:  87.5%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.353;\ttrain_accuracy:  87.5%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 0.507;\ttrain_accuracy:  68.8%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.638;\ttrain_accuracy:  62.5%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.404;\ttrain_accuracy:  87.5%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.056307;\t avg_accuracy: 44.8%\n",
      "Epoch 10/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.398;\ttrain_accuracy:  87.5%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.433;\ttrain_accuracy:  81.2%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 0.506;\ttrain_accuracy:  81.2%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.407;\ttrain_accuracy:  87.5%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 0.311;\ttrain_accuracy:  93.8%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 0.395;\ttrain_accuracy:  81.2%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 0.438;\ttrain_accuracy:  75.0%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.380;\ttrain_accuracy:  81.2%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 0.435;\ttrain_accuracy:  93.8%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.375;\ttrain_accuracy:  87.5%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 0.456;\ttrain_accuracy:  68.8%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.424;\ttrain_accuracy:  68.8%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.891;\ttrain_accuracy:  50.0%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.594;\ttrain_accuracy:  75.0%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.268;\ttrain_accuracy:  93.8%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.826;\ttrain_accuracy:  50.0%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 0.272;\ttrain_accuracy: 100.0%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.324;\ttrain_accuracy:  81.2%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.265;\ttrain_accuracy:  87.5%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.080663;\t avg_accuracy: 35.6%\n",
      "Epoch 11/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.601;\ttrain_accuracy:  62.5%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.340;\ttrain_accuracy:  81.2%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 0.427;\ttrain_accuracy:  87.5%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.260;\ttrain_accuracy:  93.8%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 0.506;\ttrain_accuracy:  68.8%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 0.474;\ttrain_accuracy:  75.0%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 0.483;\ttrain_accuracy:  81.2%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.410;\ttrain_accuracy:  87.5%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 0.299;\ttrain_accuracy:  87.5%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.324;\ttrain_accuracy:  93.8%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 0.300;\ttrain_accuracy:  93.8%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.472;\ttrain_accuracy:  62.5%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.519;\ttrain_accuracy:  75.0%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.371;\ttrain_accuracy:  81.2%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.274;\ttrain_accuracy: 100.0%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.399;\ttrain_accuracy:  93.8%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 0.360;\ttrain_accuracy:  87.5%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.344;\ttrain_accuracy:  87.5%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.279;\ttrain_accuracy:  87.5%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.067067;\t avg_accuracy: 50.6%\n",
      "Epoch 12/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.274;\ttrain_accuracy:  81.2%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.254;\ttrain_accuracy: 100.0%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 0.262;\ttrain_accuracy:  87.5%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.556;\ttrain_accuracy:  75.0%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 0.366;\ttrain_accuracy:  93.8%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 0.395;\ttrain_accuracy:  75.0%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 0.156;\ttrain_accuracy: 100.0%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.332;\ttrain_accuracy:  87.5%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 0.378;\ttrain_accuracy:  81.2%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.272;\ttrain_accuracy: 100.0%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 0.462;\ttrain_accuracy:  87.5%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.557;\ttrain_accuracy:  62.5%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.353;\ttrain_accuracy:  93.8%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.222;\ttrain_accuracy:  93.8%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.337;\ttrain_accuracy:  81.2%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.441;\ttrain_accuracy:  81.2%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 0.347;\ttrain_accuracy:  81.2%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.515;\ttrain_accuracy:  68.8%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.295;\ttrain_accuracy:  93.8%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.056278;\t avg_accuracy: 50.6%\n",
      "Epoch 13/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.442;\ttrain_accuracy:  75.0%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.421;\ttrain_accuracy:  87.5%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 0.297;\ttrain_accuracy:  93.8%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.345;\ttrain_accuracy:  81.2%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 0.382;\ttrain_accuracy:  87.5%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 0.242;\ttrain_accuracy:  87.5%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 0.295;\ttrain_accuracy:  93.8%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.320;\ttrain_accuracy:  87.5%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 0.268;\ttrain_accuracy:  93.8%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.391;\ttrain_accuracy:  75.0%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 0.155;\ttrain_accuracy: 100.0%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.534;\ttrain_accuracy:  68.8%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.259;\ttrain_accuracy: 100.0%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.749;\ttrain_accuracy:  75.0%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.380;\ttrain_accuracy:  81.2%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.371;\ttrain_accuracy:  87.5%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 0.219;\ttrain_accuracy: 100.0%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.262;\ttrain_accuracy:  87.5%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.230;\ttrain_accuracy:  93.8%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.050899;\t avg_accuracy: 57.5%\n",
      "Epoch 14/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.320;\ttrain_accuracy:  87.5%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.351;\ttrain_accuracy:  87.5%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 0.342;\ttrain_accuracy:  93.8%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.175;\ttrain_accuracy:  93.8%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 0.304;\ttrain_accuracy:  87.5%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 0.195;\ttrain_accuracy: 100.0%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 0.291;\ttrain_accuracy:  75.0%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.483;\ttrain_accuracy:  75.0%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 0.272;\ttrain_accuracy:  87.5%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.251;\ttrain_accuracy:  87.5%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 0.192;\ttrain_accuracy: 100.0%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.185;\ttrain_accuracy:  93.8%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.246;\ttrain_accuracy:  93.8%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.192;\ttrain_accuracy:  93.8%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.470;\ttrain_accuracy:  75.0%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.245;\ttrain_accuracy:  81.2%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 0.243;\ttrain_accuracy: 100.0%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.228;\ttrain_accuracy:  93.8%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.186;\ttrain_accuracy:  87.5%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.075809;\t avg_accuracy: 42.5%\n",
      "Epoch 15/15\n",
      "-------------------------------\n",
      "#    0;\ttrain_loss: 0.162;\ttrain_accuracy:  93.8%\t\t[    0/  304]\n",
      "#    1;\ttrain_loss: 0.205;\ttrain_accuracy:  93.8%\t\t[   16/  304]\n",
      "#    2;\ttrain_loss: 0.253;\ttrain_accuracy:  93.8%\t\t[   32/  304]\n",
      "#    3;\ttrain_loss: 0.314;\ttrain_accuracy:  87.5%\t\t[   48/  304]\n",
      "#    4;\ttrain_loss: 0.244;\ttrain_accuracy:  87.5%\t\t[   64/  304]\n",
      "#    5;\ttrain_loss: 0.171;\ttrain_accuracy: 100.0%\t\t[   80/  304]\n",
      "#    6;\ttrain_loss: 0.287;\ttrain_accuracy:  87.5%\t\t[   96/  304]\n",
      "#    7;\ttrain_loss: 0.269;\ttrain_accuracy:  87.5%\t\t[  112/  304]\n",
      "#    8;\ttrain_loss: 0.199;\ttrain_accuracy: 100.0%\t\t[  128/  304]\n",
      "#    9;\ttrain_loss: 0.130;\ttrain_accuracy: 100.0%\t\t[  144/  304]\n",
      "#   10;\ttrain_loss: 0.207;\ttrain_accuracy:  93.8%\t\t[  160/  304]\n",
      "#   11;\ttrain_loss: 0.274;\ttrain_accuracy:  87.5%\t\t[  176/  304]\n",
      "#   12;\ttrain_loss: 0.290;\ttrain_accuracy:  87.5%\t\t[  192/  304]\n",
      "#   13;\ttrain_loss: 0.239;\ttrain_accuracy:  93.8%\t\t[  208/  304]\n",
      "#   14;\ttrain_loss: 0.273;\ttrain_accuracy:  93.8%\t\t[  224/  304]\n",
      "#   15;\ttrain_loss: 0.334;\ttrain_accuracy:  81.2%\t\t[  240/  304]\n",
      "#   16;\ttrain_loss: 0.441;\ttrain_accuracy:  81.2%\t\t[  256/  304]\n",
      "#   17;\ttrain_loss: 0.252;\ttrain_accuracy:  93.8%\t\t[  272/  304]\n",
      "#   18;\ttrain_loss: 0.252;\ttrain_accuracy:  87.5%\t\t[  288/  304]\n",
      "Valid metrics:\n",
      "\t avg_loss: 0.077618;\t avg_accuracy: 44.8%\n",
      "Done!\n"
     ]
    }
   ],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "loss, correct = valid_test_loop(test_generator, gcn, loss_fn)\n",
    "print(f\"Test metrics:\\n\\t avg_loss: {loss:>8f};\\t avg_accuracy: {(100*correct):>0.1f}%\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test metrics:\n",
      "\t avg_loss: 0.078984;\t avg_accuracy: 38.6%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model saving"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "torch.save(gcn.state_dict(), model_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCA visualization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "class GetActivation():\n",
    "  def __init__(self, layer_name=None):\n",
    "    self.layer_name = layer_name\n",
    "    self.outputs = {}\n",
    "      \n",
    "  def __call__(self, module, module_in, module_out):\n",
    "    self.outputs[self.layer_name] = module_out.detach()\n",
    "      \n",
    "  def clear(self):\n",
    "    self.outputs = {}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "import copy \n",
    "\n",
    "gcn_test = copy.deepcopy(gcn)\n",
    "layer_name = \"fc1\"\n",
    "\n",
    "# activation = {}\n",
    "# def get_activation(name):\n",
    "#     def hook(model, input, output):\n",
    "#         activation[name] = output.detach()\n",
    "#     return hook\n",
    "# gcn.fc3.register_forward_hook(get_activation(‘fc3’))\n",
    "get_activation = GetActivation(layer_name)\n",
    "for curr_layer_name, layer in gcn_test.named_modules():\n",
    "  if curr_layer_name == layer_name:\n",
    "    layer.register_forward_hook(get_activation)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "gcn_test.eval()\n",
    "for x, y in test_generator:\n",
    "  gcn_test.fc1.register_forward_hook(get_activation)\n",
    "  out = gcn_test.forward(x)\n",
    "  print(get_activation.outputs)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'LoicGCN' object has no attribute 'outputs'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-e7d79b551295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# print(get_activation.outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 948\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LoicGCN' object has no attribute 'outputs'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Scaler = sklearn.preprocessing.StandardScaler()\n",
    "PCA = sklearn.decomposition.PCA(n_components=2)\n",
    "\n",
    "layer = \"fc3.weight\"\n",
    "last_layer_parameters = gcn.state_dict()[layer].numpy()\n",
    "# features (or samples for visualization) should be in y axis for sklearn\n",
    "last_layer_parameters = last_layer_parameters.T\n",
    "# normalization and pca decomposition\n",
    "normalized_parameters = Scaler.fit_transform(last_layer_parameters)\n",
    "pca_results = PCA.fit_transform(normalized_parameters)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "axes.scatter(x=pca_results[:, 0], y=pca_results[:, 1])\n",
    "axes.set_title(\"PCA deocmposition of layer {}\".format(layer))\n",
    "pca_results.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Scaler = sklearn.preprocessing.StandardScaler()\n",
    "PCA = sklearn.decomposition.PCA(n_components=2)\n",
    "\n",
    "layer = \"fc3.weight\"\n",
    "last_layer_parameters = gcn.state_dict()[layer].numpy()\n",
    "# features (or samples for visualization) should be in y axis for sklearn\n",
    "last_layer_parameters = last_layer_parameters.T\n",
    "# normalization and pca decomposition\n",
    "normalized_parameters = Scaler.fit_transform(last_layer_parameters)\n",
    "pca_results = PCA.fit_transform(normalized_parameters)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "axes.scatter(x=pca_results[:, 0], y=pca_results[:, 1])\n",
    "axes.set_title(\"PCA deocmposition of layer {}\".format(layer))\n",
    "pca_results.shape"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}